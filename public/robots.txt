# https://www.robotstxt.org/robotstxt.html
# Allow all crawlers
User-agent: *
Allow: /

# Disallow admin or private directories (if any)
# Disallow: /admin/
# Disallow: /private/

# Sitemap location
Sitemap: https://adityakumar.dev/sitemap.xml

# Crawl-delay (optional, helps prevent server overload)
Crawl-delay: 1

# Block specific bots (optional)
# User-agent: BadBot
# Disallow: /
